<!-- START doctoc generated TOC please keep comment here to allow auto update -->
<!-- DON'T EDIT THIS SECTION, INSTEAD RE-RUN doctoc TO UPDATE -->
**Table of Contents**  *generated with [DocToc](https://github.com/thlorenz/doctoc)*

- [Designing HCI Experiments](#designing-hci-experiments)
  - [What methodology?](#what-methodology)
  - [Ethics Approval](#ethics-approval)
  - [Experiment Design](#experiment-design)
  - [Independent Variables](#independent-variables)
  - [Dependent Variables](#dependent-variables)
  - [Other variables](#other-variables)
    - [Control Variables](#control-variables)
    - [Random variables](#random-variables)
    - [Confounding Variables](#confounding-variables)
  - [Task and Procedure](#task-and-procedure)
  - [Participants](#participants)
  - [Questionnaire Design](#questionnaire-design)
  - [Within-Subjects and Between Subjects](#within-subjects-and-between-subjects)
  - [Order effects, counter balancing, setsquares](#order-effects-counter-balancing-setsquares)
  - [Group effects and asymmetric skill transfer](#group-effects-and-asymmetric-skill-transfer)
  - [Longitudinal Studies](#longitudinal-studies)
  - [Running the Experiment](#running-the-experiment)

<!-- END doctoc generated TOC please keep comment here to allow auto update -->

# Designing HCI Experiments

## What methodology?

**Methodology:** refers to the way an experiment is designed and carried out. Science requires
strong methodology.

## Ethics Approval

Always need ethics approved before starting an experiment with human subjects.

Participants must be informed of:

1. The nature of the research
2. Methodology
3. Risks/benefits
4. Right to participate/terminate participation
5. Right to anonymity and confidentiality

## Experiment Design

Process of bringing together necessary pieces to test hypotheses. Deciding and defining variables,
tasks, procedure, participant count, etc.

What are the experimental variables? Starting with this question forces us to transition from
well-intentioned, broad and untestable questions to particular, testable questions.
We have to think of our **independent** and **dependent** variables.

## Independent Variables

Circumstance or characteristic that is manipulated or controlled. Controlled by researchers

Typically nominal scale. Can include naturally occurring attributes.

Participants cannot control or influence an independent variable.

Two tips:

1. When formulating an independent variable, express it both in terms of the circumstance or
   characteristic itself and the levels of the circumstance or characteristic chosen for
   testing. Explain the test conditions.
2. Once the name of the independent variable and names of levels has been decided, stick with these
   and stay consistent to them.
3. Don't have too many variables

Interaction effects happen when there are more than one independent variables. EAch independent
variable has a main effect, and when there is more than one, we have multiple interaction effects.

## Dependent Variables

Measured human behavior - most commonly speed/accuracy related. This depends on the human and what
the participant does.

Tips:

1. Name separately from its units.
2. Consider how measurements will be gathered, collected, organized, and stored.

Need pilot testing to ensure that data is collected and available.

Codify data to allow easy identification.

Best when we can use tools that support easy data collection and organization.

## Other variables

Control, random, and confounding variables.

### Control Variables

These are circumstances/factors that might influence dependent variables but are not under
investigation. Control by the researchers - fixed at a certain level.

### Random variables

Allowed to vary randomly. Introduces more variability, but makes results more generalizable.

Pertains to characteristics of the participants. Generally allowed to vary at random.

### Confounding Variables

Changes systematically with an independent variable - problematic and confuse results.

## Task and Procedure

When designing a good task, we have two objectives:

1. Represent-represent activities that people will actually do with the interface.
2. Discriminate-discriminate the test conditions. Be attuned to points of differentiation to expose
   benefits or problems with the test conditions.

Representative tasks improve external validity, but makes it harder to discriminate test conditions.
Increase external validity and the sake of internal validity.

High internal validity occurs when the effects observed can be attributed to test conditions. As we
add more reality to the experiment, this lessens.

## Participants

To make results generalizable, need;

1. Participants who are reflective of the generalizable audience
2. Sufficient number of participants. At least match to similar research. Can calculate by doing
   statistical tests

## Questionnaire Design

Gather demographic and experience information, and solicit opinions on devices or interaction tasks
with which they are tested.

Used for survey research. Can use close-ended questions to simplify analysis.

## Within-Subjects and Between Subjects

If each participant is tested on each level, it is within-subjects. **Repeated measures** are used
and test conditions are repeated for each participant.

If each participant is only tested on one level, the test is between-subjects. for between subject
tests, a separate group of participants is used to test each condition.

Between subjects requires more participants. It does avoid interference between test conditions ,
only have one. no need to randomize the order.

For within subjects, fewer participants are needed, but testing could take longer for one
participant. Variance due to participants predispositions is the same across test conditions, limits
differences between different participants occurring. It is not necessary to balance groups of
participants.

HCI prefers within-subjects to limit bias and get better data from fewer participants

**Mixed design** happens when doing a mixture of both.

When doing within-subject testing, have to counter the practice effect.

## Order effects, counter balancing, setsquares

**Practice effect** happens when users get better after using an interface or similar tool over
time. It might also happen that participants become tired and less good overtime, this would be a
_fatigue effect_ but is less common in HCI research.

An order effect or sequence effect needs to be combated.

Randomize and alter order of different levels for groups to counter these effects. This is _
_Counterbalancing__.

When counterbalancing a within-subjects experiment, the number of levels of the factor must divide
equally into the number of participants.

## Group effects and asymmetric skill transfer

Group effects are differences across groups. It is a problem. It means counterbalancing didn't work.

Asymmetric skill transfer happens when differences in amount of improvement are due to the order of
testing.

To avoid asymmetric skill transfer, use between-subjects design to only expose them to one test
condition because participants cannot just unlearn what they learned before.

## Longitudinal Studies

In a longitudinal study, amount of practice is an independent variable and they are tested over
time.

## Running the Experiment

Do a last pilot test with a few participants. make sure to give good instructions. Make sure that
the experimenter appears to be neutral and does not pressure or add any bias.
